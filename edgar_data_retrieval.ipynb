{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cff7ec64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, datetime, feedparser, time\n",
    "from urllib.parse import urlencode\n",
    "\n",
    "UA = \"Your Name (your.email@example.com)\"\n",
    "CUTOFF = datetime.date(2023, 1, 1)\n",
    "FORM_TYPES = {\"10-K\", \"10-Q\", \"8-K\", \"DEF 14A\", \"4\"}  # add others as needed\n",
    "\n",
    "def fetch_filings_for_cik(cik: str, form_types=FORM_TYPES, count=100):\n",
    "    cik = str(cik).zfill(10)\n",
    "    all_rows = []\n",
    "    for form in form_types:\n",
    "        start = 0\n",
    "        while True:\n",
    "            params = {\n",
    "                \"action\": \"getcompany\",\n",
    "                \"CIK\": cik,\n",
    "                \"type\": form,\n",
    "                \"owner\": \"include\",   # or \"exclude\"\n",
    "                \"count\": count,\n",
    "                \"start\": start,\n",
    "                \"output\": \"atom\"\n",
    "            }\n",
    "            url = \"https://www.sec.gov/cgi-bin/browse-edgar?\" + urlencode(params)\n",
    "            r = requests.get(url, headers={\"User-Agent\": UA}, timeout=30)\n",
    "            r.raise_for_status()\n",
    "            feed = feedparser.parse(r.text)\n",
    "\n",
    "            # No more entries?\n",
    "            if not feed.entries:\n",
    "                break\n",
    "\n",
    "            stop_here = False\n",
    "            for e in feed.entries:\n",
    "                # 'updated' or 'filing-date' both appear; keep both fallbacks\n",
    "                filed = None\n",
    "                if \"filing-date\" in e:\n",
    "                    filed = datetime.date.fromisoformat(e[\"filing-date\"])\n",
    "                else:\n",
    "                    # e.updated is RFC 822; feedparser gives a struct_time in e.updated_parsed\n",
    "                    filed = datetime.date(*e.updated_parsed[:3])\n",
    "\n",
    "                if filed < CUTOFF:\n",
    "                    stop_here = True\n",
    "                    continue\n",
    "\n",
    "                all_rows.append({\n",
    "                    \"cik\": cik,\n",
    "                    \"form\": form,\n",
    "                    \"filed\": filed.isoformat(),\n",
    "                    \"title\": e.title,\n",
    "                    \"filing_href\": e.link,              # 'Filing' page\n",
    "                    \"primary_doc_href\": next((l.href for l in e.links if l.get(\"rel\") == \"alternate\"), e.link)\n",
    "                })\n",
    "\n",
    "            if stop_here:\n",
    "                break\n",
    "            start += count\n",
    "            time.sleep(0.2)  # be nice to EDGAR\n",
    "    # Sort newest→oldest\n",
    "    all_rows.sort(key=lambda x: x[\"filed\"], reverse=True)\n",
    "    return all_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c57c24d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AAPL', 'ABBV', 'ABT', 'ACN', 'ADBE', 'AIG', 'AMD', 'AMGN', 'AMT', 'AMZN', 'AVGO', 'AXP', 'BA', 'BAC', 'BK', 'BKNG', 'BLK', 'BMY', 'BRK-B', 'C', 'CAT', 'CHTR', 'CL', 'CMCSA', 'COF', 'COP', 'COST', 'CRM', 'CSCO', 'CVS', 'CVX', 'DE', 'DHR', 'DIS', 'DUK', 'EMR', 'FDX', 'GD', 'GE', 'GILD', 'GM', 'GOOGL', 'GS', 'HD', 'HON', 'IBM', 'INTC', 'INTU', 'ISRG', 'JNJ', 'JPM', 'KO', 'LIN', 'LLY', 'LMT', 'LOW', 'MA', 'MCD', 'MDLZ', 'MDT', 'MET', 'META', 'MMM', 'MO', 'MRK', 'MS', 'MSFT', 'NEE', 'NFLX', 'NKE', 'NOW', 'NVDA', 'ORCL', 'PEP', 'PFE', 'PG', 'PLTR', 'PM', 'PYPL', 'QCOM', 'RTX', 'SBUX', 'SCHW', 'SO', 'SPG', 'T', 'TGT', 'TMO', 'TMUS', 'TSLA', 'TXN', 'UNH', 'UNP', 'UPS', 'USB', 'V', 'VZ', 'WFC', 'WMT', 'XOM']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sp100_tickers = pd.read_csv(\"data/sp100_tickers.csv\")\n",
    "sp100_tickers = sp100_tickers['Symbol'].tolist()\n",
    "print(sp100_tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04229528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "ticker_to_cik = {}\n",
    "\n",
    "data_path = \"data/company_tickers.json\"\n",
    "with open(data_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "for c_data in data.values():\n",
    "    ticker_to_cik[c_data['ticker']] = c_data['cik_str']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac826407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping AAPL: already exists → data\\edgar_documents\\AAPL_filings.json\n",
      "Skipping ABBV: already exists → data\\edgar_documents\\ABBV_filings.json\n",
      "Skipping ABT: already exists → data\\edgar_documents\\ABT_filings.json\n",
      "Skipping ACN: already exists → data\\edgar_documents\\ACN_filings.json\n",
      "Skipping ADBE: already exists → data\\edgar_documents\\ADBE_filings.json\n",
      "Skipping AIG: already exists → data\\edgar_documents\\AIG_filings.json\n",
      "Skipping AMD: already exists → data\\edgar_documents\\AMD_filings.json\n",
      "Skipping AMGN: already exists → data\\edgar_documents\\AMGN_filings.json\n",
      "Skipping AMT: already exists → data\\edgar_documents\\AMT_filings.json\n",
      "Skipping AMZN: already exists → data\\edgar_documents\\AMZN_filings.json\n",
      "Skipping AVGO: already exists → data\\edgar_documents\\AVGO_filings.json\n",
      "Skipping AXP: already exists → data\\edgar_documents\\AXP_filings.json\n",
      "Skipping BA: already exists → data\\edgar_documents\\BA_filings.json\n",
      "Fetching filings for BAC (CIK: 70858)...\n",
      "Error processing BAC: 503 Server Error: Service Unavailable for url: https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK=0000070858&type=4&owner=include&count=100&start=2100&output=atom\n",
      "Skipping BK: already exists → data\\edgar_documents\\BK_filings.json\n",
      "Skipping BKNG: already exists → data\\edgar_documents\\BKNG_filings.json\n",
      "Skipping BLK: already exists → data\\edgar_documents\\BLK_filings.json\n",
      "Skipping BMY: already exists → data\\edgar_documents\\BMY_filings.json\n",
      "Skipping BRK-B: already exists → data\\edgar_documents\\BRK-B_filings.json\n",
      "Fetching filings for C (CIK: 831001)...\n",
      "Error processing C: 503 Server Error: Service Unavailable for url: https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK=0000831001&type=4&owner=include&count=100&start=2100&output=atom\n",
      "Skipping CAT: already exists → data\\edgar_documents\\CAT_filings.json\n",
      "Skipping CHTR: already exists → data\\edgar_documents\\CHTR_filings.json\n",
      "Skipping CL: already exists → data\\edgar_documents\\CL_filings.json\n",
      "Skipping CMCSA: already exists → data\\edgar_documents\\CMCSA_filings.json\n",
      "Skipping COF: already exists → data\\edgar_documents\\COF_filings.json\n",
      "Skipping COP: already exists → data\\edgar_documents\\COP_filings.json\n",
      "Skipping COST: already exists → data\\edgar_documents\\COST_filings.json\n",
      "Skipping CRM: already exists → data\\edgar_documents\\CRM_filings.json\n",
      "Skipping CSCO: already exists → data\\edgar_documents\\CSCO_filings.json\n",
      "Skipping CVS: already exists → data\\edgar_documents\\CVS_filings.json\n",
      "Skipping CVX: already exists → data\\edgar_documents\\CVX_filings.json\n",
      "Skipping DE: already exists → data\\edgar_documents\\DE_filings.json\n",
      "Skipping DHR: already exists → data\\edgar_documents\\DHR_filings.json\n",
      "Skipping DIS: already exists → data\\edgar_documents\\DIS_filings.json\n",
      "Skipping DUK: already exists → data\\edgar_documents\\DUK_filings.json\n",
      "Skipping EMR: already exists → data\\edgar_documents\\EMR_filings.json\n",
      "Skipping FDX: already exists → data\\edgar_documents\\FDX_filings.json\n",
      "Skipping GD: already exists → data\\edgar_documents\\GD_filings.json\n",
      "Skipping GE: already exists → data\\edgar_documents\\GE_filings.json\n",
      "Skipping GILD: already exists → data\\edgar_documents\\GILD_filings.json\n",
      "Skipping GM: already exists → data\\edgar_documents\\GM_filings.json\n",
      "Skipping GOOGL: already exists → data\\edgar_documents\\GOOGL_filings.json\n",
      "Fetching filings for GS (CIK: 886982)...\n",
      "Error processing GS: 503 Server Error: Service Unavailable for url: https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK=0000886982&type=4&owner=include&count=100&start=2100&output=atom\n",
      "Skipping HD: already exists → data\\edgar_documents\\HD_filings.json\n",
      "Skipping HON: already exists → data\\edgar_documents\\HON_filings.json\n",
      "Skipping IBM: already exists → data\\edgar_documents\\IBM_filings.json\n",
      "Skipping INTC: already exists → data\\edgar_documents\\INTC_filings.json\n",
      "Skipping INTU: already exists → data\\edgar_documents\\INTU_filings.json\n",
      "Skipping ISRG: already exists → data\\edgar_documents\\ISRG_filings.json\n",
      "Skipping JNJ: already exists → data\\edgar_documents\\JNJ_filings.json\n",
      "Fetching filings for JPM (CIK: 19617)...\n",
      "Error processing JPM: 503 Server Error: Service Unavailable for url: https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK=0000019617&type=4&owner=include&count=100&start=2100&output=atom\n",
      "Skipping KO: already exists → data\\edgar_documents\\KO_filings.json\n",
      "Skipping LIN: already exists → data\\edgar_documents\\LIN_filings.json\n",
      "Skipping LLY: already exists → data\\edgar_documents\\LLY_filings.json\n",
      "Skipping LMT: already exists → data\\edgar_documents\\LMT_filings.json\n",
      "Skipping LOW: already exists → data\\edgar_documents\\LOW_filings.json\n",
      "Skipping MA: already exists → data\\edgar_documents\\MA_filings.json\n",
      "Skipping MCD: already exists → data\\edgar_documents\\MCD_filings.json\n",
      "Skipping MDLZ: already exists → data\\edgar_documents\\MDLZ_filings.json\n",
      "Skipping MDT: already exists → data\\edgar_documents\\MDT_filings.json\n",
      "Skipping MET: already exists → data\\edgar_documents\\MET_filings.json\n",
      "Skipping META: already exists → data\\edgar_documents\\META_filings.json\n",
      "Skipping MMM: already exists → data\\edgar_documents\\MMM_filings.json\n",
      "Skipping MO: already exists → data\\edgar_documents\\MO_filings.json\n",
      "Skipping MRK: already exists → data\\edgar_documents\\MRK_filings.json\n",
      "Fetching filings for MS (CIK: 895421)...\n",
      "Error processing MS: 503 Server Error: Service Unavailable for url: https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK=0000895421&type=4&owner=include&count=100&start=2100&output=atom\n",
      "Skipping MSFT: already exists → data\\edgar_documents\\MSFT_filings.json\n",
      "Skipping NEE: already exists → data\\edgar_documents\\NEE_filings.json\n",
      "Skipping NFLX: already exists → data\\edgar_documents\\NFLX_filings.json\n",
      "Skipping NKE: already exists → data\\edgar_documents\\NKE_filings.json\n",
      "Skipping NOW: already exists → data\\edgar_documents\\NOW_filings.json\n",
      "Skipping NVDA: already exists → data\\edgar_documents\\NVDA_filings.json\n",
      "Skipping ORCL: already exists → data\\edgar_documents\\ORCL_filings.json\n",
      "Skipping PEP: already exists → data\\edgar_documents\\PEP_filings.json\n",
      "Skipping PFE: already exists → data\\edgar_documents\\PFE_filings.json\n",
      "Skipping PG: already exists → data\\edgar_documents\\PG_filings.json\n",
      "Skipping PLTR: already exists → data\\edgar_documents\\PLTR_filings.json\n",
      "Skipping PM: already exists → data\\edgar_documents\\PM_filings.json\n",
      "Skipping PYPL: already exists → data\\edgar_documents\\PYPL_filings.json\n",
      "Skipping QCOM: already exists → data\\edgar_documents\\QCOM_filings.json\n",
      "Skipping RTX: already exists → data\\edgar_documents\\RTX_filings.json\n",
      "Skipping SBUX: already exists → data\\edgar_documents\\SBUX_filings.json\n",
      "Skipping SCHW: already exists → data\\edgar_documents\\SCHW_filings.json\n",
      "Skipping SO: already exists → data\\edgar_documents\\SO_filings.json\n",
      "Skipping SPG: already exists → data\\edgar_documents\\SPG_filings.json\n",
      "Skipping T: already exists → data\\edgar_documents\\T_filings.json\n",
      "Skipping TGT: already exists → data\\edgar_documents\\TGT_filings.json\n",
      "Skipping TMO: already exists → data\\edgar_documents\\TMO_filings.json\n",
      "Skipping TMUS: already exists → data\\edgar_documents\\TMUS_filings.json\n",
      "Skipping TSLA: already exists → data\\edgar_documents\\TSLA_filings.json\n",
      "Skipping TXN: already exists → data\\edgar_documents\\TXN_filings.json\n",
      "Skipping UNH: already exists → data\\edgar_documents\\UNH_filings.json\n",
      "Skipping UNP: already exists → data\\edgar_documents\\UNP_filings.json\n",
      "Skipping UPS: already exists → data\\edgar_documents\\UPS_filings.json\n",
      "Skipping USB: already exists → data\\edgar_documents\\USB_filings.json\n",
      "Skipping V: already exists → data\\edgar_documents\\V_filings.json\n",
      "Skipping VZ: already exists → data\\edgar_documents\\VZ_filings.json\n",
      "Skipping WFC: already exists → data\\edgar_documents\\WFC_filings.json\n",
      "Skipping WMT: already exists → data\\edgar_documents\\WMT_filings.json\n",
      "Skipping XOM: already exists → data\\edgar_documents\\XOM_filings.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "output_dir = Path(\"data/edgar_documents\")\n",
    "\n",
    "for ticker in sp100_tickers:\n",
    "    outpath = output_dir / f\"{ticker}_filings.json\"\n",
    "\n",
    "    # Skip if already downloaded\n",
    "    if outpath.exists():\n",
    "        print(f\"Skipping {ticker}: already exists → {outpath}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        cik = ticker_to_cik[ticker]\n",
    "        print(f\"Fetching filings for {ticker} (CIK: {cik})...\")\n",
    "        rows = fetch_filings_for_cik(cik)\n",
    "\n",
    "        with open(outpath, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(rows, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "        print(f\"✅ Saved {len(rows)} filings for {ticker} → {outpath}\")\n",
    "\n",
    "        time.sleep(0.3)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {ticker}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4539b03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed AAPL, downloaded: 167/167\n",
      "Completed ABBV, downloaded: 232/232\n",
      "Completed ABT, downloaded: 232/232\n",
      "Completed ACN, downloaded: 734/734\n",
      "Completed ADBE, downloaded: 321/321\n",
      "Completed AIG, downloaded: 438/438\n",
      "Completed AMD, downloaded: 245/245\n",
      "Completed AMGN, downloaded: 294/294\n",
      "Completed AMT, downloaded: 228/228\n",
      "Completed AMZN, downloaded: 276/276\n",
      "Completed AVGO, downloaded: 224/224\n",
      "Completed AXP, downloaded: 362/362\n",
      "Completed BA, downloaded: 310/310\n",
      "Completed BK, downloaded: 316/316\n",
      "Completed BKNG, downloaded: 204/204\n",
      "Completed BLK, downloaded: 153/153\n",
      "Completed BMY, downloaded: 258/258\n",
      "Completed BRK-B, downloaded: 180/180\n",
      "Completed CAT, downloaded: 301/301\n",
      "Completed CHTR, downloaded: 285/285\n",
      "Completed CL, downloaded: 243/243\n",
      "Completed CMCSA, downloaded: 263/263\n",
      "Completed COF, downloaded: 395/395\n",
      "Completed COP, downloaded: 278/278\n",
      "Completed COST, downloaded: 211/211\n",
      "Completed CRM, downloaded: 936/936\n",
      "Completed CSCO, downloaded: 299/299\n",
      "Completed CVS, downloaded: 223/223\n",
      "Completed CVX, downloaded: 257/257\n",
      "Completed DE, downloaded: 146/146\n",
      "Completed DHR, downloaded: 342/342\n",
      "Completed DIS, downloaded: 269/269\n",
      "Completed DUK, downloaded: 284/284\n",
      "Completed EMR, downloaded: 170/170\n",
      "Completed FDX, downloaded: 174/174\n",
      "Completed GD, downloaded: 329/329\n",
      "Completed GE, downloaded: 233/233\n",
      "Completed GILD, downloaded: 238/238\n",
      "Completed GM, downloaded: 183/183\n",
      "Completed GOOGL, downloaded: 502/502\n",
      "Completed HD, downloaded: 292/292\n",
      "Completed HON, downloaded: 367/367\n",
      "Completed IBM, downloaded: 333/333\n",
      "Completed INTC, downloaded: 297/297\n",
      "Completed INTU, downloaded: 407/407\n",
      "Completed ISRG, downloaded: 300/301\n",
      "Completed JNJ, downloaded: 315/315\n",
      "Completed KO, downloaded: 244/244\n",
      "Completed LIN, downloaded: 192/192\n",
      "Completed LLY, downloaded: 471/471\n",
      "Completed LMT, downloaded: 211/211\n",
      "Completed LOW, downloaded: 233/233\n",
      "Completed MA, downloaded: 294/294\n",
      "Completed MCD, downloaded: 275/275\n",
      "Completed MDLZ, downloaded: 151/151\n",
      "Completed MDT, downloaded: 185/185\n",
      "Completed MET, downloaded: 404/404\n",
      "Completed META, downloaded: 785/785\n",
      "Completed MMM, downloaded: 259/259\n",
      "Completed MO, downloaded: 166/166\n",
      "Completed MRK, downloaded: 257/257\n",
      "Completed MSFT, downloaded: 370/370\n",
      "Completed NEE, downloaded: 266/266\n",
      "Completed NFLX, downloaded: 666/666\n",
      "Completed NKE, downloaded: 184/184\n",
      "Completed NOW, downloaded: 538/538\n",
      "Completed NVDA, downloaded: 354/354\n",
      "Completed ORCL, downloaded: 211/211\n",
      "Completed PEP, downloaded: 179/179\n",
      "Completed PFE, downloaded: 398/398\n",
      "Completed PG, downloaded: 498/498\n",
      "Completed PLTR, downloaded: 312/312\n",
      "Completed PM, downloaded: 237/237\n",
      "Completed PYPL, downloaded: 220/220\n",
      "Completed QCOM, downloaded: 273/273\n",
      "Completed RTX, downloaded: 189/189\n",
      "Completed SBUX, downloaded: 164/164\n",
      "Completed SCHW, downloaded: 375/375\n",
      "Completed SO, downloaded: 440/440\n",
      "Completed SPG, downloaded: 305/305\n",
      "Completed T, downloaded: 624/624\n",
      "Completed TGT, downloaded: 187/187\n",
      "Completed TMO, downloaded: 300/300\n",
      "Completed TMUS, downloaded: 351/351\n",
      "Completed TSLA, downloaded: 155/155\n",
      "Completed TXN, downloaded: 233/233\n",
      "Completed UNH, downloaded: 454/454\n",
      "Completed UNP, downloaded: 479/479\n",
      "Completed UPS, downloaded: 205/205\n",
      "Completed USB, downloaded: 466/466\n",
      "Completed V, downloaded: 200/200\n",
      "Completed VZ, downloaded: 971/971\n",
      "Completed WFC, downloaded: 1027/1027\n",
      "Completed WMT, downloaded: 651/651\n",
      "Completed XOM, downloaded: 204/204\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "# output dir\n",
    "ROOT_DIR = \"data/edgar_documents\"\n",
    "FILINGS_NAME = \"_filings.json\"\n",
    "\n",
    "UA = \"Your Name (your.email@example.com)\"\n",
    "session = requests.Session()\n",
    "session.headers.update({\"User-Agent\": UA})\n",
    "\n",
    "def extract_file_link(url):\n",
    "    resp = session.get(url, timeout=30)\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "    tables = soup.select(\"table.tableFile\")\n",
    "    doc_table = tables[0]\n",
    "    first_table_row = doc_table.select(\"tr\")[1]\n",
    "    raw_link = first_table_row.find('a', href=True)['href']\n",
    "    formatted_raw_link = raw_link.split(\"doc=\")[1] if \"doc=\" in raw_link else raw_link\n",
    "    doc_url = \"https://www.sec.gov\" + formatted_raw_link\n",
    "    return doc_url\n",
    "\n",
    "def download_document(url: str, dest: Path) -> bool:\n",
    "    if dest.exists() and dest.stat().st_size > 0:\n",
    "        return True\n",
    "    doc_link = extract_file_link(url)\n",
    "    resp = session.get(doc_link, timeout=30)\n",
    "    if resp.status_code == 200:\n",
    "        dest.parent.mkdir(exist_ok=True)\n",
    "        dest.write_bytes(resp.content)\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "for ticker in sp100_tickers:\n",
    "    filing_path = Path(ROOT_DIR + '/' + ticker + FILINGS_NAME)\n",
    "    if filing_path.exists():\n",
    "        with open(filing_path, 'r') as f:\n",
    "            filings = json.load(f)\n",
    "        \n",
    "        SAVE_PATH = ROOT_DIR + '/' + ticker\n",
    "        os.makedirs(SAVE_PATH, exist_ok=True)\n",
    "        \n",
    "        total_downloaded = 0\n",
    "        for filing in filings:\n",
    "            file_name = filing['form'].replace(\" \", '-') + '_' + filing['filed']\n",
    "            file_path = Path(ROOT_DIR).joinpath(ticker, file_name)\n",
    "            url = filing['filing_href']\n",
    "            total_downloaded  += download_document(url, dest=file_path)\n",
    "        print(f\"Completed {ticker}, downloaded: {total_downloaded}/{len(filings)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
